---
title: "253 Final Project"
author: "Melissa Blum, Andrew Padgett, Tomas Panek"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r, echo=FALSE}
#plotting and exploring
library(tidyverse) #for plotting and summarizing
library(GGally) #for nice scatterplot matrix 
library(ggridges) #for joy/ridge plots
library(corrplot) #for basic correlation matrix plot
library(naniar) #for exploring missing values
library(pdp) #for partial dependence plots, MARS models
library(rpart.plot) #for plotting decision trees
library(vip) #for importance plots
library(pROC) #for ROC curves
library(plotROC) #for plotting ROC curves

#making things look nice
library(lubridate) #for nice dates
library(knitr) #for nice tables
library(scales) #for nice labels on graphs
library(gridExtra) #for arranging plots
library(broom) #for nice model output
library(janitor) #for nice names

#data
library(ISLR) #for data
library(moderndive) #for data
library(rattle) #weather data

#modeling
library(rsample) #for splitting data
library(recipes) #for keeping track of transformations
library(caret) #for modeling
library(leaps) #for variable selection
library(glmnet) #for LASSO
library(earth) #for MARS models
library(rpart) #for decision trees
library(randomForest) #for bagging and random forests

theme_set(theme_minimal())
```

I read in the diabetes hospital readmission data in case that's what we end up using. There's one paper that's been published using the same data, so I put the link to that paper below. They used a logistic regression model with many of the variables in the dataset to predict hospital readmissions of diabetic patients - I think it would be cool to try other types of models and see if we can find one that makes more accurate predictions.

archive.ics.uci.edu/ml/machine-learning-databases/00296/

```{r}
diabetic_data <- read_csv("diabetic_data.csv", 
    na = "?")
```

```{r}
head(diabetic_data)
```

Links to data and paper:

http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008#
https://www.hindawi.com/journals/bmri/2014/781670/

Table using count function for medical specialty diag 

```{r}
diabetic_data %>% count(medical_specialty) %>% arrange(n)

```

```{r}

# Perform logistic regression
med_spec <- train(
    as.factor(readmitted1) ~ medical_specialty,
    data = diabetic_data %>%
        mutate(readmitted1 = (readmitted != "no")),
    method = "glm",
    family = "binomial",
    metric = "Accuracy",
    na.action = na.omit
)
```

```{r}
summary(med_spec)
```
ok to drop

create new variables for particular diagnostic codes

428, 414, 427
276, 250, 401, 496, 403, 

```{r}
diabetic_data %>% count(diag_1) %>% arrange(desc(n))
```
```{r}
diabetic_data %>% count(diag_2) %>% arrange(desc(n))
```

```{r}
diabetic_data %>% count(diag_3) %>% arrange(desc(n))
```

```{r, fig.height = 18, fig.width = 10}
diabetic_data %>% 
  select(-encounter_id, -patient_nbr, -medical_specialty, -diag_1, -diag_2, -diag_3) %>% 
  select_if(is.character) %>% 
  pivot_longer(cols = everything(),names_to = "variable", values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_bar() +
    scale_y_log10(breaks = scales::trans_breaks("log10",
                                               function(x) 10^x),
                 labels = scales::comma) + 
  # annotation_logticks(sides = "l") +
    coord_flip()+
    facet_wrap(ncol = 2, vars(variable), scales = "free")
```

Variables to exclude: troglitazone, tolbutamide, tolazamide, rosiglatazone, nateglinide, acetohexamide, metformin-piag, citoglipton, examide, 

```{r}
diabetic_data %>% 
  select(-encounter_id, -patient_nbr) %>% 
  select_if(is.numeric) %>% 
  pivot_longer(cols = everything(),names_to = "variable", values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(vars(variable), scales = "free")
```


fct_lump
n = 5 keep the most common 5 values, lump everything else into other category

```{r}
diabetic_edited_diag <- diabetic_data %>%
  mutate(diag_1_new = fct_lump(diag_1, n = 5),
         diag_2_new = fct_lump(diag_2, n = 5),
         diag_3_new = fct_lump(diag_3, n = 5),
         admission_type_id = as.factor(admission_type_id),
         admission_source_id = as.factor(admission_source_id),
         discharge_disposition_id = as.factor(discharge_disposition_id),
         readmitted_30 = ifelse(readmitted == "<30", 1, 0))
```


```{r}
diabetic_edited <- diabetic_data %>%
  mutate(admission_type_id = as.factor(admission_type_id),
         admission_source_id = as.factor(admission_source_id),
         discharge_disposition_id = as.factor(discharge_disposition_id),
         readmitted_30 = ifelse(readmitted == "<30", 1, 0))
  
```

```{r}

```


#Modeling

#Logistic Regression

```{r}
set.seed(253)

diabetic_split_diag <- diabetic_edited_diag %>% 
  initial_split(prop = .7, strata = readmitted_30)

diag_train <- training(diabetic_split_diag)
diag_test <-testing(diabetic_split_diag)

```

```{r}
# Perform logistic regression
log_reg <- train(
    readmitted_30 ~ select(-encounter_id, -patient_nbr),
    data = diabetic_edited_diag,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 5),
    metric = "Accuracy",
    na.action = na.omit
)
```


argument | meaning
-------- | -------- | -------------
`y ~ x1 + ... + xp` | model formula
`data` | training data after splitting into train and test 
`method` | model fitting method - `glm` implements various generalized linear models, of which logistic regression is one 
`family` | Using `family = "binomial"` fits logistic regression models (`family = "gaussian"` is equivalent to `method = "lm"`)
`trControl` | how to split the data using the `trainControl` function. We continue to use `method = "cv"` and `number` is the number of folds
`metric` | Accuracy will be used to evaluate models
`na.action` | how to treat missing values, `na.omit` will remove any row with missing values

## Examining coefficients

```{r, eval=FALSE}
#model output
summary(logistic_model)

#cv accuracy metrics
logistic_model$results
logistic_model$resample #details for each fold
```


## Predicting and evaluation

The `newdata` can be either a small dataset you create or it can be a test dataset or something like that. 

```{r, eval=FALSE}
# Make PROBABILITY predictions
predict(logistic_model, newdata = ___, type = "prob")

# Make CLASSIFICATIONS (using a default 0.5 probability threshold). This is the default if you don't include type.
predict(logistic_model, newdata = ___, type = "raw")

# Confusion matrix (using a default 0.5 probability threshold)
# Reference is the response variable from the training data
# In the positive argument, specify the category of interest (eg: "Yes", "1", "pass")
classifications <- predict(logistic_model, newdata = predict_data, type = "raw")
confusionMatrix(data = classifications, 
  reference = ___, 
  positive = ___)
```

