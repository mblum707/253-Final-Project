---
title: "253 Final Project"
author: "Melissa Blum, Andrew Padgett, Tomas Panek"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r, echo=FALSE}
#plotting and exploring
library(tidyverse) #for plotting and summarizing
library(GGally) #for nice scatterplot matrix 
library(ggridges) #for joy/ridge plots
library(corrplot) #for basic correlation matrix plot
library(naniar) #for exploring missing values
library(pdp) #for partial dependence plots, MARS models
library(rpart.plot) #for plotting decision trees
library(vip) #for importance plots
library(pROC) #for ROC curves
library(plotROC) #for plotting ROC curves

#making things look nice
library(lubridate) #for nice dates
library(knitr) #for nice tables
library(scales) #for nice labels on graphs
library(gridExtra) #for arranging plots
library(broom) #for nice model output
library(janitor) #for nice names

#data
library(ISLR) #for data
library(moderndive) #for data
library(rattle) #weather data

#modeling
library(rsample) #for splitting data
library(recipes) #for keeping track of transformations
library(caret) #for modeling
library(leaps) #for variable selection
library(glmnet) #for LASSO
library(earth) #for MARS models
library(rpart) #for decision trees
library(randomForest) #for bagging and random forests

theme_set(theme_minimal())
```

I read in the diabetes hospital readmission data in case that's what we end up using. There's one paper that's been published using the same data, so I put the link to that paper below. They used a logistic regression model with many of the variables in the dataset to predict hospital readmissions of diabetic patients - I think it would be cool to try other types of models and see if we can find one that makes more accurate predictions.

archive.ics.uci.edu/ml/machine-learning-databases/00296/

```{r}
diabetic_data <- read_csv("diabetic_data.csv", 
    na = "?")
```

```{r}
head(diabetic_data)
```

Links to data and paper:

http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008#
https://www.hindawi.com/journals/bmri/2014/781670/

Table using count function for medical specialty diag 

```{r}
diabetic_data %>% count(medical_specialty) %>% arrange(n)

```

```{r}

# Perform logistic regression
med_spec <- train(
    as.factor(readmitted1) ~ medical_specialty,
    data = diabetic_data %>%
        mutate(readmitted1 = (readmitted != "no")),
    method = "glm",
    family = "binomial",
    metric = "Accuracy",
    na.action = na.omit
)
```

```{r}
summary(med_spec)
```
ok to drop

create new variables for particular diagnostic codes

428, 414, 427
276, 250, 401, 496, 403, 

```{r}
diabetic_data %>% count(diag_1) %>% arrange(desc(n))
```
```{r}
diabetic_data %>% count(diag_2) %>% arrange(desc(n))
```

```{r}
diabetic_data %>% count(diag_3) %>% arrange(desc(n))
```

```{r, fig.height = 18, fig.width = 10}
diabetic_data %>% 
  select(-encounter_id, -patient_nbr, -medical_specialty, -diag_1, -diag_2, -diag_3) %>% 
  select_if(is.character) %>% 
  pivot_longer(cols = everything(),names_to = "variable", values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_bar() +
    scale_y_log10(breaks = scales::trans_breaks("log10",
                                               function(x) 10^x),
                 labels = scales::comma) + 
  # annotation_logticks(sides = "l") +
    coord_flip()+
    facet_wrap(ncol = 2, vars(variable), scales = "free")
```

Variables to exclude: troglitazone, tolbutamide, tolazamide, rosiglatazone, nateglinide, acetohexamide, metformin-piag, citoglipton, examide, 

```{r}
diabetic_data %>% 
  select(-encounter_id, -patient_nbr) %>% 
  select_if(is.numeric) %>% 
  pivot_longer(cols = everything(),names_to = "variable", values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(vars(variable), scales = "free")
```


```{r}
diabetic_edited_diag <- diabetic_data %>%
  mutate(diag_1_new = fct_lump(diag_1, n = 5),
         diag_2_new = fct_lump(diag_2, n = 5),
         diag_3_new = fct_lump(diag_3, n = 5),
         admission_type_id = as.factor(admission_type_id),
         admission_source_id = as.factor(admission_source_id),
         discharge_disposition_id = as.factor(discharge_disposition_id),
         readmitted_30 = ifelse(readmitted == "<30", 1, 0)) %>%
  select(-weight, -payer_code, -encounter_id, -patient_nbr, -troglitazone, -tolbutamide, -tolazamide, -rosiglitazone, -repaglinide, -nateglinide, -acetohexamide, -`metformin-pioglitazone`, -citoglipton, -examide, -miglitol, -`metformin-rosiglitazone`,-`glimepiride-pioglitazone`, -`glipizide-metformin`,-chlorpropamide, -acarbose, -diag_1, -diag_2, -diag_3, -readmitted, -medical_specialty, -`glyburide-metformin`) %>%
  drop_na()


```


```{r}
diabetic_edited <- diabetic_data %>%
  mutate(admission_type_id = as.factor(admission_type_id),
         admission_source_id = as.factor(admission_source_id),
         discharge_disposition_id = as.factor(discharge_disposition_id),
         readmitted_30 = ifelse(readmitted == "<30", 1, 0))
  
```


#Model Fitting

```{r}
set.seed(253)

diabetic_split_diag <- diabetic_edited_diag %>% 
  initial_split(prop = .5, strata = readmitted_30)

diag_train <- training(diabetic_split_diag)
diag_test <-testing(diabetic_split_diag)

```

##Logistic Regression

```{r}
# Perform logistic regression
log_reg <- train(
    as.factor(readmitted_30) ~ .,
    data = diag_train,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 5),
    metric = "Accuracy",
    na.action = na.omit
)
```

##Lasso Logistic 

```{r}
set.seed(253)

lambda_grid <- 10^seq(-4, -2, length = 100)

log_lasso <- train(
    as.factor(readmitted_30) ~ .,
    data = diag_train,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 5),
    tuneGrid = data.frame(alpha = 1, 
                          lambda = lambda_grid),
    metric = "Accuracy",
    na.action = na.omit
)

```

##Classification Tree

```{r}
set.seed(253)

cp_grid <- 10^seq(-4, -2, length = 100)

class_tree <- train(
  as.factor(readmitted_30)~.,
  data = diag_train,
  method = "rpart",
  tuneGrid = data.frame(cp = cp_grid),
  trControl = trainControl(method = "cv", number = 5),
  metric = "Accuracy",
  na.action = na.omit
)
```

##Random Forest

```{r}
set.seed(253)

# mtry_grid <- seq(2, __, length = __)

rand_for <- train(
  as.factor(readmitted_30) ~ .,
  data = diag_train, 
  method = "rf",
  trControl = trainControl(method = "oob"),
  tuneGrid = data.frame(mtry = c(2)),
  ntree = 100, 
  importance = TRUE,
  nodesize = 5, 
  metric = "Accuracy",
  na.action = na.omit
)
```

##KNN

```{r}
# set.seed(253)
# 
# k_grid = c(1,5,25,125,625)
# 
# knn <- train(
#   as.factor(readmitted_30) ~ .,
#   data = diag_train,
#   method = "knn",
#   tuneGrid = data.frame(k = k_grid),
#   trControl = trainControl(method = "cv", number = 5),
#   metric = "Accuracy",
#   na.action = na.omit
# )
```

#Model Evaluation on Training Data

##Logistic Regression

```{r}
summary(log_reg)
log_reg$results
```

```{r}
classifications <- predict(log_reg, newdata = diag_train, type = "raw")
confusionMatrix(data = classifications, 
  reference = as.factor(diag_train$readmitted_30), 
  positive = "1")
```

```{r}
diag_train %>% 
  mutate(PredRead =  predict(log_reg, type = "prob")$"1") %>%
  ggplot(aes(d = as.integer(readmitted_30), m = PredRead)) + 
  geom_roc(labelround = 2, size = 1,
           linealpha = .5, pointalpha = .8) +
  geom_abline(slope = 1, intercept = 0, color = "gray")

diag_train %>%
  mutate(PredRead =  predict(log_reg, type = "prob")$"1") %>%
  roc(readmitted_30 ~ PredRead, data=.) %>%
  auc()
```

##Lasso Logistic

```{r}
log_lasso$bestTune
log_lasso$results
```

```{r}
coef(log_lasso$finalModel, 0.00129155)
```

```{r}
classifications <- predict(log_lasso, newdata = diag_train, type = "raw")
confusionMatrix(data = classifications, 
  reference = as.factor(diag_train$readmitted_30), 
  positive = "1")
```

```{r}
diag_train %>% 
  mutate(PredRead =  predict(log_lasso, type = "prob")$"1") %>%
  ggplot(aes(d = as.integer(readmitted_30), m = PredRead)) + 
  geom_roc(labelround = 2, size = 1,
           linealpha = .5, pointalpha = .8) +
  geom_abline(slope = 1, intercept = 0, color = "gray")

diag_train %>%
  mutate(PredRead =  predict(log_lasso, type = "prob")$"1") %>%
  roc(readmitted_30 ~ PredRead, data=.) %>%
  auc()
```

##Classification Tree

```{r}
class_tree$bestTune
class_tree$results
```

```{r}
vip(class_tree$finalModel, num_features = 16, bar = FALSE)
```

```{r}
rpart.plot(class_tree$finalModel)
```

```{r}
classifications <- predict(class_tree, newdata = diag_train, type = "raw")
confusionMatrix(data = classifications, 
  reference = as.factor(diag_train$readmitted_30), 
  positive = "1")
```

```{r}
diag_train %>% 
  mutate(PredRead =  predict(class_tree, type = "prob")$"1") %>%
  ggplot(aes(d = as.integer(readmitted_30), m = PredRead)) + 
  geom_roc(labelround = 2, size = 1,
           linealpha = .5, pointalpha = .8) +
  geom_abline(slope = 1, intercept = 0, color = "gray")

diag_train %>%
  mutate(PredRead =  predict(class_tree, type = "prob")$"1") %>%
  roc(readmitted_30 ~ PredRead, data=.) %>%
  auc()
```

##Random Forest

```{r}
rand_for$bestTune
rand_for$results
```

```{r}
vip(rand_for$finalModel, num_features = 16, bar = FALSE)
```

```{r}
classifications <- predict(rand_for, newdata = diag_train, type = "raw")
confusionMatrix(data = classifications, 
  reference = as.factor(diag_train$readmitted_30), 
  positive = "1")
```

```{r}
diag_train %>% 
  mutate(PredRead =  predict(rand_for, type = "prob")$"1") %>%
  ggplot(aes(d = as.integer(readmitted_30), m = PredRead)) + 
  geom_roc(labelround = 2, size = 1,
           linealpha = .5, pointalpha = .8) +
  geom_abline(slope = 1, intercept = 0, color = "gray")

diag_train %>%
  mutate(PredRead =  predict(rand_for, type = "prob")$"1") %>%
  roc(readmitted_30 ~ PredRead, data=.) %>%
  auc()
```

##KNN

```{r}
# knn$bestTune
# knn$results
# ```
# 
# ```{r}
# classifications <- predict(knn, newdata = diag_train, type = "raw")
# confusionMatrix(data = classifications, 
#   reference = as.factor(diag_train$readmitted_30), 
#   positive = "1")
# ```
# 
# ```{r}
# diag_train %>% 
#   mutate(PredRead =  predict(knn, type = "prob")$"1") %>%
#   ggplot(aes(d = as.integer(readmitted_30), m = PredRead)) + 
#   geom_roc(labelround = 2, size = 1,
#            linealpha = .5, pointalpha = .8) +
#   geom_abline(slope = 1, intercept = 0, color = "gray")
# 
# diag_train %>%
#   mutate(PredRead =  predict(knn, type = "prob")$"1") %>%
#   roc(readmitted_30 ~ PredRead, data=.) %>%
#   auc()
```

#Model Evaluation on Testing Data

